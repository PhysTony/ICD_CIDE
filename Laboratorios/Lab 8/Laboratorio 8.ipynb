{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MRWL5MOlYocc"
   },
   "source": [
    "\n",
    "\n",
    "# Laboratorio 8\n",
    "\n",
    "Empezaremos a ver conceptos básicos de ML y sus diferencias con econometría"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HDLwlNMj093R"
   },
   "source": [
    "## ¿Qué es ML?\n",
    "\n",
    "El aprendizaje automático ( ML ) es el estudio científico de algoritmos y modelos estadísticos que los sistemas informáticos utilizan para realizar una tarea específica sin utilizar instrucciones explícitas, basándose en patrones e inferencias. Se considera un subconjunto de la inteligencia artificial. Los algoritmos de aprendizaje automático construyen un modelo matemático basado en datos de muestra, conocidos como datos de entrenamiento, para hacer predicciones o decisiones sin estar programados explícitamente para realizar la tarea.\n",
    "\n",
    "https://towardsdatascience.com/what-is-machine-learning-a-visual-explanation-14642b90429f\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¿Para qué utilizar aprendizaje estadístico?\n",
    "\n",
    "Hay dos razones por las que queremos utilizar las técnicas de aprendizaje estadístico:\n",
    "\n",
    "* **Predicción**:  En el caso de aprendizaje estadístico, si tenemos un modelo $\\hat{f}(X)$, podemos estimar $y$:\n",
    "\n",
    "$$\n",
    "E(y) = \\hat{f}(X) + E(\\epsilon) = \\hat{f}(X)\n",
    "$$\n",
    " asumiendo que $E(\\epsilon)=0$.\n",
    "\n",
    "* **Inferencia**: queremos *entender* cuáles variables $X_1, X_2, \\cdots, X_p$ afectan el resultado $y$, y de qué forma lo hacen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ozdDQZuo1A27"
   },
   "source": [
    "### ¿Explicar o predecir?\n",
    "El punto de partida en un proyecto de análisis de datos es el siguiente:\n",
    "\n",
    "(1) comprender las relaciones o\n",
    "\n",
    "(2) obtener el mejor nivel de precisión posible. \n",
    "\n",
    "Galit Shmueli en su artículo [“Explain or Predict”](https://www.stat.berkeley.edu/~aldous/157/Papers/shmueli.pdf) sugiere la distinción entre modelado explicativo y predictivo. \n",
    "\n",
    "- El \"modelo explicativo\" utiliza métodos estadísticos para probar las relaciones causales. \n",
    "- Por el contrario, el \"modelado predictivo\" es el proceso de aplicar un modelo estadístico o un algoritmo de minería de datos a los datos con el fin de predecir observaciones nuevas o futuras. \n",
    "\n",
    "Como dijo Jerome H. Friedman en su artículo, \"uno de los usos más comunes de los datos es la predicción\". Si el objetivo es probar la hipótesis causal, el propósito \"explicativo\" es más importante que el propósito predictivo, y viceversa. \n",
    "- La econometría, desde su génesis, se ha enfatizado más en la prueba de hipótesis y la identificación de causalidad.\n",
    "- Por el contrario, el aprendizaje automático tiene como objetivo la predicción y tiene un éxito impresionante.\n",
    "\n",
    "\n",
    "Las preguntas causales requieren algunos diseños de generación de datos y no pueden calcularse solo a partir de los datos. Mira las siguientes preguntas:\n",
    "- ¿Cuál es la eficacia de un fármaco determinado en una población determinada?\n",
    "- ¿Qué fracción de delitos se puede evitar si se implementa una nueva política?\n",
    "- ¿Cuál fue la causa de la muerte de un paciente debido a ciertas complicaciones médicas?\n",
    "- ¿Cómo utilizar el análisis de datos para demostrar que un empleador es culpable de discriminación en la contratación?\n",
    "\n",
    "Por el contrario, las preguntas predictivas son más del tipo:\n",
    "- ¿Puedo predecir cuándo una persona podría reincidir en delitos?\n",
    "- ¿Puedo predecir el riesgo de una persona de contraer diabetes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xN727WUR4DFe"
   },
   "source": [
    "### ¿Qué pueden aprender uno del otro? \n",
    "\n",
    "Hal Varian, economista jefe de Google Inc., pregunta qué puede aprender un economista del aprendizaje automático y qué puede aprender el aprendizaje automático de la econometría. Existen técnicas de aprendizaje automático [\"new tricks\"](https://www.aeaweb.org/articles?id=10.1257/jep.28.2.3) que deben adoptar los econometristas y las perspectivas econométricas que las técnicas de aprendizaje automático pueden considerar.\n",
    "\n",
    "1. Curso de dimensionalidad (no puedo tener más columnas que filas) - importa para ML\n",
    "    - Grados de libertad\n",
    "2. Sobreespecificación  - importa para ML\n",
    "3. La forma funcional debería sustentada en la teoría - no importa tanto para ML\n",
    "4. Multicolinealidad\n",
    "\n",
    "#### Econometría de ML \n",
    "- Regularización para evitar el sobreajuste: los modelos complejos tienden a ajustarse demasiado bien a los datos de entrenamiento, pero no se ajustan a los datos desconocidos. Las técnicas de regularización incorporan la función de pérdida para penalizar un modelo con demasiados parámetros. La palabra \"regularización\" significa hacer que la predicción sea regular o aceptable, para que pueda predecir datos desconocidos.\n",
    "\n",
    "- Validación cruzada: Técnica utilizada para evaluar los resultados de un análisis estadístico y garantizar que son independientes de la partición entre datos de entrenamiento y prueba. Consiste en repetir y calcular la media aritmética obtenida de las medidas de evaluación sobre diferentes particiones. Se utiliza en entornos donde el objetivo principal es la predicción y se quiere estimar la precisión de un modelo que se llevará a cabo a la práctica\n",
    "\n",
    "- Promedio de modelos: técnica específica para mejorar la capacidad predictiva mediante la combinación de predicciones de un conjunto de modelos. Por ejemplo, se utiliza para promediar coeficientes de regresión en múltiples modelos con el objetivo final de capturar el efecto general de una variable.\n",
    "\n",
    "- Análisis textual: Es un proceso de recopilación de datos para comprender las formas en que se puede interpretar el lenguaje humano\n",
    "\n",
    "\n",
    "#### ML de Econometría\n",
    "\n",
    "- Inferencia causal : El proceso de sacar una conclusión sobre una conexión causal basada en las condiciones de ocurrencia de un efecto. Ver Susan Athey https://www.tandfonline.com/doi/abs/10.1080/01621459.2017.1319839?journalCode=uasa20\n",
    "- Variable de confusión: Una variable de confusión es una influencia externa que cambia el efecto de una variable dependiente e independiente. Por ejemplo, si está investigando si la falta de sueño conduce a la pérdida de peso, la falta de sueño es su variable independiente y la pérdida de peso es su variable dependiente. Una posible variable de confusión puede ser el consumo de pastillas para dormir\n",
    "- Experimentos naturales: Un experimento natural es un estudio empírico en el que los individuos están expuestos a las condiciones experimentales y de control determinadas por la naturaleza u otros factores fuera del control de los investigadores. La forma más simple es similar a la asignación aleatoria.\n",
    "- Diseño de regresión discontinua (DR): popular en econometría, ciencias políticas y epidemiología, un diseño de regresión discontinua identifica los efectos causales de las intervenciones para aquellos que están por encima y por debajo de un umbral. \n",
    "- Diferencia en diferencias (DID): DID es un diseño cuasi-experimental para estimar el efecto causal de una intervención o tratamiento específico (como la aprobación de una ley, la promulgación de una política o la implementación de un programa a gran escala) comparando los cambios en los resultados. a lo largo del tiempo entre una población que está inscrita en un programa (el grupo de intervención) y una población que no lo está (el grupo de control). \n",
    "- Variables instrumentales: una variable instrumental es una tercera variable, Z, que se utiliza en el análisis de regresión cuando tiene variables endógenas, variables que están influenciadas por otras variables en el modelo. La variable instrumental se utiliza para tener en cuenta el comportamiento inesperado entre variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_l7F33uj-gsa"
   },
   "source": [
    "Para más info pueden consultar\n",
    "\n",
    "https://towardsdatascience.com/from-econometrics-to-machine-learning-ee182f3a45d7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¿Cómo aprendemos el proceso de generación de datos? \n",
    "\n",
    "\n",
    "* Si queremos comparar modelos, necesitamos una métrica que nos permita decir si un modelo es mejor que otro.\n",
    "\n",
    "\n",
    "* En modelos de regresión, la métrica estándar es el error cuadrático medio (MSE):\n",
    "$$\n",
    "MSE = \\frac{1}{N}\\sum_i (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "\n",
    "* Así: un modelo $A$ as mejor que un modelo $B$ si $MSE_A < MSE_B$\n",
    "\n",
    "\n",
    "* Alternativamente, si queremos hacer supuestos sobre la distribución del término de error $\\epsilon$, podemos utilizar (el logaritmo de) la función de verosimilitud, $LL(\\theta)$ en el caso de un modelo paramétrico con parámetros a estimar $\\mathbf \\theta$.\n",
    "\n",
    "    * En este caso el mejor modelo es el que tiene un *mayor loglikelihood LL*.\n",
    "\n",
    "\n",
    "* En el caso paramétrico, lineal en los parámetros $Y = X\\beta + \\epsilon$, ya sabemos que el **estimador de mínimos cuadrados ordinarios** (OLS, por sus siglas en inglés), es la solución al problema de minimizar el MSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Y en el caso de modelos de clasificación:\n",
    "\n",
    "* En modelos con supuestos sobre la distribución (ejemplo: modelos *Logit* o *Probit*), se puede utilizar la respectiva verosimilitud.\n",
    "\n",
    "\n",
    "* Pero en general podemos usar la **tasa de error**:\n",
    "$$\n",
    "\\frac{1}{N}\\sum_i I(y_i \\neq \\hat{y}_i)\n",
    "$$\n",
    "\n",
    "    * Es decir, para cada observación, sabemos si fue clasificada correcta o incorrectmente.  Si fue incorrecta $y_i \\neq \\hat{y}_i$ la variable indicador toma el valor $1$, si fue correcta toma el valor $0$.\n",
    "\n",
    "\n",
    "* Los modelos de clasificación suelen tener asociada una probabilidad condicional: $Prob(y_i \\in C_k| x_i)$, es decir, la probabilidad de que una obsevación $i$ sea del tipo $k$, condicional en el valor de sus regresores $x_i = x_{1i},x_{2i}, \\cdots, x_{pi},$.\n",
    "\n",
    "\n",
    "* En estos casos, el clasificador que minimiza la tasa de error se conoce como el **clasificador de Bayes** (\"Bayes classifier\"), y asigna cada observación $i$ a la clase que tiene una mayor probabilidad de ocurrir $k^* = argmax_k Prob(y_i \\in C_k| x_i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos paramétricos y modelos no paramétricos\n",
    "\n",
    "* **Modelo paramétrico:** si tiene un *número fijo de parámetros* y se hacen supuestos sobre la forma funcional del proceso de generación de datos $f(x)$.\n",
    "\n",
    "    * Ejemplo1: $y = \\beta_0 + \\beta_1 x_1 + \\epsilon$\n",
    "    \n",
    "    * Ejemplo2: $Prob(y=1|x,\\beta) = \\Phi(x'\\beta)$, donde $\\Phi()$ es la función de distribución acumulativa de una variable aleatoria normal estándar.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* **Modelo no paramétrico:** si no se hacen supuestos sobre la forma funcional del proceso de generación de datos.\n",
    "\n",
    "    * **K-nearest neighbors**: \n",
    "        \n",
    "        * Queremos clasificar la observación $i$.\n",
    "        * Para hacerlo miramos las categorías de las $K$ observaciones más cercanas de acuerdo con las variables independientes $x$, se obtienen las fracciones empíricas (ej. $1/3$ de los K vecinos son de la categoría $1$ y $2/3$ son de la categoría $0$):\n",
    "        $$\n",
    "        Prob \\left(y_i=c|\\mathbf{x_i},K \\right) = \\frac{1}{K}\\sum_{j \\in N_K(x_i)} I(y_j =c)\n",
    "        $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R0KfDO34Yh8S"
   },
   "source": [
    "\n",
    "\n",
    "# Un pipeline simple de ML\n",
    "\n",
    "Los primeros pasos a seguir para ajustar un modelo de predicción usando Python son:\n",
    "\n",
    "1. **Preparar los datos**. Como hemos visto, para llegar a este punto hemos aprendido a cargar los datos de diferentes maneras y de diferentes fuentes, a limpiarlos, a organizarlos, agruparlos, etc, y a hacer un análisis exploratorio de datos con el objetivo de entender mejor los datos y el problema.\n",
    "\n",
    "2. **Identificar la variable objetivo**. Si ya está definida, identificarla y separarla del resto de las variables independientes. Si no está definida, construírla a partir del contexto del problema.\n",
    "\n",
    "3. **División train/test de los datos**. La división puede ser aleatoria o predefinida según el contexto, con muestreo, despendiendo de la naturaleza del problema.\n",
    "\n",
    "4. **Instanciación del modelo para el entrenamiento**. Usaremos una librería para cargar los algoritmos predefinidos llamada sklearn. \n",
    "\n",
    "5. **Ajuste del modelo**. Utilizaremos el método ```fit``` del modelo.\n",
    "\n",
    "6. **Predicción**. Utilización del método ```predict``` del modelo.\n",
    "\n",
    "7. **Elección y implemetación de un métrica**. Para poder estimar el error de prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PyDW9dpbR98R"
   },
   "source": [
    "\n",
    "\n",
    "Primeramente vamos a llamar a la librería ```scikit-learn```, ésta contiene varios módulos en donde están cargadas las diferentes herramientas de ML.\n",
    "Por ejemplo de model_selection obtendremos el método ```train_test_split```, de ```linear_model``` obtendremos el objeto ```LinearRegression``` la cuál contiene el algorítmo de regresión lineal cargado, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Ku2MRUn_ermJ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5HXUKiXzemiP"
   },
   "source": [
    "\n",
    "\n",
    "## Preparar los datos: valores de las casas de los suburbios de Boston\n",
    "\n",
    "* Fuente: https://www.kaggle.com/c/boston-housing \n",
    "\n",
    "Lo podemos leer de la siguiente forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 371
    },
    "id": "gbGCFNgZWCr6",
    "outputId": "2441d69f-1e78-4675-a2e7-22f8f1cff373"
   },
   "outputs": [],
   "source": [
    "column_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "\n",
    "df = pd.read_csv('files/Boston.csv', header=None, \n",
    "                 delimiter=r\"\\s+\", names=column_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YFPll5aZUDlE"
   },
   "source": [
    "\n",
    "\n",
    "El archivo contiene datos de las casas de los suburbios de Boston, cada registro representa una casa y tiene varios atributos.\n",
    "\n",
    "Tanto caracteristicas físicas de la casa como atributos demográficos de la zona: número de habitaciones, el procentaje de crimen por zona, el ratio de alumno/maestro, etc... \n",
    "\n",
    "Estos datos ya vienen en una estructura que, a parte de estructurada de manera adecuada, no viene con registro repetidos, nulos, o atípicos. Podemos decir que fueron previamente tratados y que están listos para entrenar un modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "FEwn_Wx9kLUr"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296.0   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242.0   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242.0   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222.0   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  MEDV  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     17.8  392.83   4.03  34.7  \n",
       "3     18.7  394.63   2.94  33.4  \n",
       "4     18.7  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0xO3I8xm539D"
   },
   "source": [
    "\n",
    "\n",
    "## Identificar la variable objetivo\n",
    "En este caso la variable objetivo está dada, no tenemos que hacer una transformación para obtenerla, simplemente la obtenemos a partir de la columna del dataframe ```df```. Las demás columnas ya son variables númericas que pueden servir como *input* de un modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "W8A0cGTq57LA"
   },
   "outputs": [],
   "source": [
    "features = list(df.columns)[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "p5xFi_rD6dbf"
   },
   "outputs": [],
   "source": [
    "X = df[features]\n",
    "y = df.MEDV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rghisksijg44"
   },
   "source": [
    "\n",
    "\n",
    "## Hacer la separacion train/test\n",
    "El método ```train_test_split``` regresa 4 outputs, las features divididas en entrenamiento y prueba, y la variable objetivo divida en entrenamiento y prueba respectivamente. Por convención (como en muchos casos en Python) en este contexto les llamamos ```X_train```, ```X_test```, ```y_train```, ```y_test```.\n",
    "\n",
    "Por defecto se hace una particion aleatoria del 75% de entrenamiento, 25% de prueba.\n",
    "\n",
    "¿En todos los casos es válido hacer un muestreo aleatorio? ¿En qué casos cambiarías el porcentaje de observaciones en cada muestra?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "0bIoh104j7ex"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "379"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HUx-Kgqqkr1G"
   },
   "source": [
    "\n",
    "\n",
    "## Instanciación del modelo para el entrenamiento\n",
    "Se instancia el objeto en donde van a cargar los métodos y atributos que harán el entrenamiento y ajuste para crear un modelo de aprendizaje de máquina.\n",
    "\n",
    "En este caso ```LinearRegression``` es una instancia de la clase ```LinearRegression```, que contiene el algoritmo para obtener los coeficientes de mínimos de cuadrados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "LY7ATuo9kvDS"
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pw2GztJ60TTi"
   },
   "source": [
    "\n",
    "\n",
    "## Ajuste del modelo\n",
    "\n",
    "Para ejecutar el algoritmo se hace a través de un método llamado **fit**.\n",
    "\n",
    "Una vez hecha una separación de entrenamiento y de prueba, realizamos el ajuste o entrenamiento, es decir, a partir de una muestra de los datos se van a obtener los coeficientes que minimizan el error.\n",
    "\n",
    "Estos coeficientes define un modelo específico generado por esos datos. Por claridad lo vamos a guardar en una objeto llamado lr_model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "EdttOM8n0TTj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeficientes:  36.47015247742959 [-1.07817012e-01  5.03354114e-02  4.07927430e-02  2.67942463e+00\n",
      " -1.77994899e+01  3.70618389e+00 -1.01944854e-03 -1.51998383e+00\n",
      "  3.24187621e-01 -1.24790717e-02 -9.03981814e-01  1.03764695e-02\n",
      " -5.74510392e-01]\n"
     ]
    }
   ],
   "source": [
    "lr_model = lr.fit(X_train, y_train)\n",
    "print ('Coeficientes: ',  lr_model.intercept_, lr_model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HBCaynZH0TTn"
   },
   "source": [
    "\n",
    "\n",
    "## Predicción\n",
    "\n",
    "Una vez que ha sido entrenado el modelo, podemos probar con una observación de una muestra diferente, o sea, con la muestra de prueba. Notese que la muestra de prueba no ha sido usada en el método fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "rBKMQ6gq0TTn"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([42.34241904, 27.32515993,  5.3930836 , 20.13726285, 12.83325123,\n",
       "       14.6703969 , 13.20389637, 33.44486181, 25.57312819, 18.28021741])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_lr = lr_model.predict(X_test)\n",
    "predictions_lr[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "rlOe76Rbp25F"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([42.34241904, 27.32515993,  5.3930836 , 20.13726285, 12.83325123,\n",
       "       14.6703969 , 13.20389637, 33.44486181, 25.57312819, 18.28021741,\n",
       "       28.62497935, 16.31726977, 22.73438626, 24.48419419, 23.42821045,\n",
       "       20.7887315 , 29.02753009, 34.27401483, 20.92823223, 24.65732849,\n",
       "       31.78101221, 24.35712111, 24.8953182 , 34.42930807, 17.42799605,\n",
       "       14.33559525, 20.28782068, 25.29721234, 16.97530042, 23.34443048,\n",
       "       27.76226912, 32.05314112, 23.06194422, 21.31094325, 32.67690334,\n",
       "       22.64243682, 13.05594805, 13.28200901, 29.88934964,  3.42065607,\n",
       "       26.1269553 , 24.56200153, 19.90468948, 18.00570123, 18.52371939,\n",
       "       33.58499227, 22.75031269, 16.8948118 , 31.86328775, 22.89641876,\n",
       "        8.0920779 , 32.94585775, 19.84296548, 20.31805233, 20.62026805,\n",
       "       35.60357212, 20.68890994, 11.58450051, 19.15560097, 20.60838965,\n",
       "       18.71426834, 17.04111141, 15.3733053 , 30.93200789, 34.63901422,\n",
       "       -5.05334501, 27.79806656, 13.30705039, 24.52331089, 22.69061051,\n",
       "       16.69724045, 17.6164398 , 16.3745648 , 10.98298175, 22.00858476,\n",
       "       23.92729683, 27.16163683, 19.41288137, 30.44823193,  6.61400149,\n",
       "       22.40148628, 20.70969926, 20.6203664 , 32.4514134 , 30.95266918,\n",
       "       19.83042593, 21.76193415, 17.39698768, 14.6899458 , 27.11136238,\n",
       "       14.28844273,  9.5408724 , 33.18037747, 22.87171045,  0.34331339,\n",
       "       32.13213327, 26.49715132, 23.97606057, 38.52430765, 21.55973455,\n",
       "       30.68232482, 26.5964682 , 14.01402531, 19.32998738, 18.3802249 ,\n",
       "       13.90500597,  8.04213592, 20.63335818, 32.52592537, 21.29634054,\n",
       "       18.4915052 , 34.09015543, 18.4955686 , 17.29456997, 24.97967191,\n",
       "       21.41784721, 36.32320119, 18.99171558, 38.24460875, 33.43339649,\n",
       "        7.85289981, 40.63336806, 29.01249324, 22.63500719, 20.0837516 ,\n",
       "       37.02551711, 19.14638217])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "272    24.4\n",
       "80     28.0\n",
       "449    13.0\n",
       "283    50.0\n",
       "251    24.8\n",
       "       ... \n",
       "229    31.5\n",
       "172    23.1\n",
       "120    22.0\n",
       "155    15.6\n",
       "433    14.3\n",
       "Name: MEDV, Length: 379, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oOKrOIfpfeDS"
   },
   "source": [
    "\n",
    "\n",
    "Observamos que el output del método **predict** es un array en donde están las predicciones de los valores de las casas.\n",
    "\n",
    "El output dependerá del problema, si es supervisado de regresión o de clasificación.\n",
    "\n",
    "¿Cómo sería el output en un contexto de apredizaje supervisado de clasificación? ¿Y de regresión? ¿Y de aprendizaje no supervisado?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bxB7UzJx0TTs"
   },
   "source": [
    "\n",
    "\n",
    "## Elección de un métrica\n",
    "La métrica que se elige es para medir qué tan bien tu modelo va a predecir cuando se tengan datos no observados previamente. Más adelante veremos los detalles de las distintas métricas que existen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ydmu6NeeKeds"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.013385826771646"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "7R2Cwpq30TTs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error medio absoluto:  3.244313394654667\n",
      "Error cuadrático medio:  18.154414769970018\n"
     ]
    }
   ],
   "source": [
    "print ('Error medio absoluto: ', mean_absolute_error(y_test,predictions_lr))\n",
    "print ('Error cuadrático medio: ', mean_squared_error(y_test,predictions_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KyVmCPvuhR3o"
   },
   "source": [
    "\n",
    "\n",
    "## Conclusión\n",
    "\n",
    "Como se ha mencionado este es un ejemplo introductorio del marco de trabajo básico del que partiremos.\n",
    "A partir de aquí vamos a profundizar en cada uno de los pasos que hemos mencionado, a responder varias preguntas que han quedado inconclusas y estudiar problemas de naturaleza distinta como aprendizaje supervisado de clasificación, de regresión y apredizaje no supervisado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## El algoritmo KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El K-NN es un algoritmo de aprendizaje supervisado, es decir, que a partir de un juego de datos inicial su objetivo será el de clasificar correctamente todas las instancias nuevas. El juego de datos típico de este tipo de algoritmos está formado por varios atributos descriptivos y un solo atributo objetivo (también llamado clase).\n",
    "\n",
    "En esta implementación usaremos el algoritmo KNN para asignar las etiquetas de cada pieza de ropa que se encuentra en la imagen (vamos a usar imágenes de piezas de ropa).\n",
    "\n",
    "Destacar que K-NN es muy sensible a:\n",
    "1. La variable k, de modo que con valores distintos de k podemos obtener resultados también muy distintos. Este valor suele fijarse tras un proceso de pruebas con varias instancias.\n",
    "\n",
    "2. La métrica de similitud utilizada, puesto que esta influirá, fuertemente, en las relaciones de cercanía que se irán estableciendo en el proceso de construcción del algoritmo. La métrica de distancia puede llegar a contener pesos que nos ayudarán a calibrar el algoritmo de clasificación, convirtiéndola, de hecho, en una métrica personalizada.\n",
    "\n",
    "Vemos cómo influye el valor de k:\n",
    "\n",
    "```Para k = 1 el algoritmo clasificará la bola con signo + como blanca\n",
    "Para k = 2 el algoritmo no tiene criterio para clasificar la bola con signo +\n",
    "Para k >= 3 el algoritmo clasificará la bola con signo + como negra```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_init_train: Esta función que asegura que la variable train_data de la clase KNN, contiene nuestro conjunto de entrenamiento, tenga el formato float, y luego extrae las características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    " def _init_train(self,train_data):\n",
    "    dim2 = train_data.shape[1]*train_data.shape[2]\n",
    "    self.train_data = np.array(train_data.reshape([train_data.shape[0], dim2]), dtype = 'float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get_k_neighbours: Recibe el conjunto de test que queremos etiquetar (Test_data) y hace lo siguiente:\n",
    "\n",
    "1. Cambia de dimensiones de las imágenes de la misma manera que lo hemos hecho con el conjunto de entrenamiento.\n",
    "\n",
    "2. Calcula la distancia entre las características del test_data con las del train_data.\n",
    "\n",
    "3. Guarda en la variable de clase self.neighbors las K etiquetas de las imágenes más próximas para cada muestra del test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_neighbours(self, test_data, k):\n",
    "    dim2 = test_data.shape[1]*test_data.shape[2]\n",
    "    test_data = np.array(test_data.reshape([test_data.shape[0], dim2]), dtype = 'float')\n",
    "    distances = cdist(test_data, self.train_data, 'euclidean')\n",
    "    self.neighbors = np.array([]).reshape([0, k])\n",
    "    \n",
    "    for img in distances:\n",
    "        idx = np.argsort(img)[:k]\n",
    "        labels = self.labels[idx].reshape([1, k])\n",
    "        self.neighbors = np.vstack([self.neighbors, labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get_class: Comprueba cuál es la etiqueta que más veces ha aparecido en la variable de clase neighbors para cada imagen del conjunto de tes y devuelve un array con esta clase para cada imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class(self):\n",
    "\n",
    "    if self.neighbors.shape[1] == 1:\n",
    "        return self.neighbors\n",
    "    else:\n",
    "        clase = np.array([])\n",
    "        for img in self.neighbors:\n",
    "            _, indexes, counts = np.unique(img, return_counts = True, return_index=True)\n",
    "            maxVal_index = np.where(counts == np.amax(counts))\n",
    "            clase = np.append(clase, img[np.sort(indexes[maxVal_index])[0]])\n",
    "        \n",
    "        return clase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict: Toma como entrada el conjunto de test que queremos etiquetar (test_data) y el número de vecinos que queremos tener en cuenta (k), busca sus vecinos utilizando get_k_neighbours, y devuelve la clase más representativa utilizando get_class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    " def predict(self, test_data, k):\n",
    "    self.get_k_neighbours(test_data, k)\n",
    "    return self.get_class()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EJERCICIOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Escriba un programa de Python usando Scikit-learn para dividir el conjunto de datos del iris en un 80 % de datos de entrenamiento y un 20 % de datos de prueba. Del total de 150 registros, el conjunto de entrenamiento contendrá 120 registros y el conjunto de prueba contiene 30 de esos registros. Entrene o ajuste los datos en el modelo y calcule la precisión del modelo utilizando el algoritmo del vecino más cercano K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'iloc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_30848/1087970535.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#Drop id column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0miris\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miris\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miris\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miris\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#Split arrays or matrices into train and test subsets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'iloc'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.model_selection import train_test_split  \n",
    "\n",
    "iris = pd.read_csv(\"iris.csv\")\n",
    "#Drop id column\n",
    "iris = iris.drop(['Id'],axis=1,inplace=True)\n",
    "X = iris.iloc[:, :-1].values\n",
    "y = iris.iloc[:, 4].values\n",
    "#Split arrays or matrices into train and test subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20) \n",
    "knn = KNeighborsClassifier(n_neighbors=7)  \n",
    "knn.fit(X_train, y_train)   \n",
    "# Calculate the accuracy of the model \n",
    "print(\"Accuracy of the model:\")\n",
    "print(knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. dividir el conjunto de datos del iris en un 70 % de datos de entrenamiento y un 30 % de datos de prueba. Del total de 150 registros, el conjunto de entrenamiento contendrá 105 registros y el conjunto de prueba contiene 45 de esos registros. Prediga la respuesta para el conjunto de datos de prueba (SepalLengthCm, SepalWidthCm, PetalLengthCm, PetalWidthCm) utilizando el algoritmo K vecino más cercano. Utilice 5 como número de vecinos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response for test dataset:\n",
      "['Iris-versicolor' 'Iris-versicolor' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-versicolor' 'Iris-virginica' 'Iris-virginica' 'Iris-versicolor'\n",
      " 'Iris-virginica' 'Iris-setosa' 'Iris-setosa' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-setosa' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-virginica' 'Iris-setosa' 'Iris-virginica'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-virginica' 'Iris-setosa'\n",
      " 'Iris-versicolor' 'Iris-setosa' 'Iris-virginica' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-virginica' 'Iris-setosa' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-setosa' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-setosa' 'Iris-versicolor' 'Iris-setosa' 'Iris-versicolor'\n",
      " 'Iris-setosa']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "iris = pd.read_csv(\"iris.csv\")\n",
    "#Drop id column\n",
    "iris.head()\n",
    "iris = iris.drop('Id',axis=1)\n",
    "X = iris.iloc[:, :-1].values\n",
    "y = iris.iloc[:, 4].values\n",
    "#Split arrays or matrices into random train and test subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)\n",
    "'''\n",
    "print(\"\\n70% train data:\")\n",
    "print(X_train)\n",
    "print(y_train)\n",
    "print(\"\\n30% test data:\")\n",
    "print(X_test)\n",
    "print(y_test)\n",
    "'''\n",
    "#Create KNN Classifier\n",
    "#Number of neighbors to use by default for kneighbors queries.\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "#Train the model using the training sets\n",
    "knn.fit(X_train, y_train)\n",
    "#Predict the response for test dataset\n",
    "print(\"Response for test dataset:\")\n",
    "y_pred = knn.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal.length</th>\n",
       "      <th>sepal.width</th>\n",
       "      <th>petal.length</th>\n",
       "      <th>petal.width</th>\n",
       "      <th>variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal.length  sepal.width  petal.length  petal.width variety\n",
       "0           5.1          3.5           1.4          0.2  Setosa\n",
       "1           4.9          3.0           1.4          0.2  Setosa\n",
       "2           4.7          3.2           1.3          0.2  Setosa\n",
       "3           4.6          3.1           1.5          0.2  Setosa\n",
       "4           5.0          3.6           1.4          0.2  Setosa"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. divida el conjunto de datos del iris en un 80 % de datos de entrenamiento y un 20 % de datos de prueba. Del total de 150 registros, el conjunto de entrenamiento contendrá 120 registros y el conjunto de prueba contiene 30 de esos registros. Entrene o ajuste los datos en el modelo y calcule la precisión del modelo utilizando el algoritmo del vecino más cercano K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model:\n",
      "0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.model_selection import train_test_split  \n",
    "iris = pd.read_csv(\"iris.csv\")\n",
    "#Drop id column\n",
    "iris = iris.drop('Id',axis=1)\n",
    "X = iris.iloc[:, :-1].values\n",
    "y = iris.iloc[:, 4].values\n",
    "#Split arrays or matrices into train and test subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20) \n",
    "knn = KNeighborsClassifier(n_neighbors=7)  \n",
    "knn.fit(X_train, y_train)   \n",
    "# Calculate the accuracy of the model \n",
    "print(\"Accuracy of the model:\")\n",
    "print(knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Clase 4 Intro ML I.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
